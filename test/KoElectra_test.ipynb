{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "KoElectra_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Electra Model\n",
        "\n",
        "Since we will use Electra to embed document contexts, we need to test Electra model. \\\n",
        "As namuwiki is based on Korean, we will use KOElectra(<https://github.com/monologg/KoELECTRA>) \\\n",
        "This Code is tested on Colab, So it might be not available on other environments.\n",
        "\n"
      ],
      "metadata": {
        "id": "GtB4L9yiT5fo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install mxnet\r\n",
        "!pip install gluonnlp pandas tqdm\r\n",
        "!pip install sentencepiece\r\n",
        "!pip install transformers"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.24)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6IIf4VmTwQl",
        "outputId": "807a6ac2-8522-4b20-c3a2-e3cc34852af1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\r\n",
        "!wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-08-19 05:13:30--  https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6027:18::a27d:4812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/374ftkec978br3d/ratings_train.txt [following]\n",
            "--2021-08-19 05:13:30--  https://www.dropbox.com/s/dl/374ftkec978br3d/ratings_train.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucacf19fa080ad8ef9424c92ff0b.dl.dropboxusercontent.com/cd/0/get/BUhjQyI6P3kkjOVWpb2j1L5iQdRUz4_CY9wkFhrXIcreR4qZ6oFj8cBnC59Lk4AUuCHni_r9cSg4nIlSKaYwTDdcP0NL1WQHhIJNzG4GTDeahZ7FcYfJescyP9BC29DZdeeBq8RuFbyl1UnVgFMSLeNS/file?dl=1# [following]\n",
            "--2021-08-19 05:13:30--  https://ucacf19fa080ad8ef9424c92ff0b.dl.dropboxusercontent.com/cd/0/get/BUhjQyI6P3kkjOVWpb2j1L5iQdRUz4_CY9wkFhrXIcreR4qZ6oFj8cBnC59Lk4AUuCHni_r9cSg4nIlSKaYwTDdcP0NL1WQHhIJNzG4GTDeahZ7FcYfJescyP9BC29DZdeeBq8RuFbyl1UnVgFMSLeNS/file?dl=1\n",
            "Resolving ucacf19fa080ad8ef9424c92ff0b.dl.dropboxusercontent.com (ucacf19fa080ad8ef9424c92ff0b.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:601a:15::a27d:70f\n",
            "Connecting to ucacf19fa080ad8ef9424c92ff0b.dl.dropboxusercontent.com (ucacf19fa080ad8ef9424c92ff0b.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14628807 (14M) [application/binary]\n",
            "Saving to: ‘ratings_train.txt?dl=1.1’\n",
            "\n",
            "ratings_train.txt?d 100%[===================>]  13.95M  13.4MB/s    in 1.0s    \n",
            "\n",
            "2021-08-19 05:13:32 (13.4 MB/s) - ‘ratings_train.txt?dl=1.1’ saved [14628807/14628807]\n",
            "\n",
            "--2021-08-19 05:13:32--  https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6027:18::a27d:4812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/977gbwh542gdy94/ratings_test.txt [following]\n",
            "--2021-08-19 05:13:32--  https://www.dropbox.com/s/dl/977gbwh542gdy94/ratings_test.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3edf1d4ba4016121479ad6004c.dl.dropboxusercontent.com/cd/0/get/BUhoF8dl-J9mYF_AP7O4-uOzMiKOd3gVH7PYvnE0wxOY7QucNJRNHMqrDtrF7NtUnMicdgrhJWTxWQuh4-YhRf5ZernqtuyPAWC746PUNQpt8hVC3jgb3CQiMEMgbG46kC-6slILir0KxJqLPEwKkJ_K/file?dl=1# [following]\n",
            "--2021-08-19 05:13:33--  https://uc3edf1d4ba4016121479ad6004c.dl.dropboxusercontent.com/cd/0/get/BUhoF8dl-J9mYF_AP7O4-uOzMiKOd3gVH7PYvnE0wxOY7QucNJRNHMqrDtrF7NtUnMicdgrhJWTxWQuh4-YhRf5ZernqtuyPAWC746PUNQpt8hVC3jgb3CQiMEMgbG46kC-6slILir0KxJqLPEwKkJ_K/file?dl=1\n",
            "Resolving uc3edf1d4ba4016121479ad6004c.dl.dropboxusercontent.com (uc3edf1d4ba4016121479ad6004c.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to uc3edf1d4ba4016121479ad6004c.dl.dropboxusercontent.com (uc3edf1d4ba4016121479ad6004c.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893335 (4.7M) [application/binary]\n",
            "Saving to: ‘ratings_test.txt?dl=1.1’\n",
            "\n",
            "ratings_test.txt?dl 100%[===================>]   4.67M  6.79MB/s    in 0.7s    \n",
            "\n",
            "2021-08-19 05:13:34 (6.79 MB/s) - ‘ratings_test.txt?dl=1.1’ saved [4893335/4893335]\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSY8t_dDXmeI",
        "outputId": "db3904b3-d576-490a-dffc-43d476d5f543"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries\n",
        "\n",
        "Using transformers, we can load model easily."
      ],
      "metadata": {
        "id": "xpwiQlJFWw2I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import gluonnlp as nlp\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from transformers import ElectraModel, ElectraTokenizer, DistilBertModel"
      ],
      "outputs": [],
      "metadata": {
        "id": "XUo6iiXHWx53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Pretrained KoElectra Model"
      ],
      "metadata": {
        "id": "XAXYVkOAbZFS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\r\n",
        "electra = ElectraModel.from_pretrained(\"monologg/koelectra-small-v3-discriminator\")\r\n",
        "bert = DistilBertModel.from_pretrained('monologg/distilkobert')\r\n",
        "\r\n",
        "print(sum(p.numel() for p in electra.parameters() if p.requires_grad))\r\n",
        "print(sum(p.numel() for p in bert.parameters() if p.requires_grad))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at monologg/distilkobert were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14056192\n",
            "27803904\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr8ZBjC-bZf6",
        "outputId": "83f8cf44-27b1-4bf0-a919-cc70a88cade7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Read data\r\n",
        "\r\n",
        "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)\r\n",
        "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)\r\n",
        "\r\n",
        "dataset_test[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['굳 ㅋ', '1']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuogg7wDkGRq",
        "outputId": "d0590e9c-c8e8-4217-cdb1-ae7467f9297b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Dataset\n",
        "\n",
        "To train model, we have to process original data with tokenizer. \\\n",
        "For this propose, use Dataset class in pyotrch."
      ],
      "metadata": {
        "id": "YhNgse5KloYZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class Rating(Dataset):\n",
        "  def __init__(self, data, tokenizer, max_len):\n",
        "    self.comments = [tokenizer(d[0], padding='max_length', max_length=max_len, return_tensors= 'pt', truncation=True) for d in data]\n",
        "    self.labels = [d[1] for d in data]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.comments[idx], torch.tensor([int(self.labels[idx])])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ],
      "outputs": [],
      "metadata": {
        "id": "p2z4xlFUlojq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Trian settings\n",
        "epoch = 5\n",
        "max_len = 64\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "log_interval = 500\n",
        "max_grad_norm = 0.5\n",
        "\n",
        "device = 'cuda'"
      ],
      "outputs": [],
      "metadata": {
        "id": "m3kT39gUPJqm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dataset_train = Rating(dataset_train, tokenizer, max_len)\n",
        "dataset_test = Rating(dataset_test, tokenizer, max_len)"
      ],
      "outputs": [],
      "metadata": {
        "id": "nI6q2Op7YAZ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "trainLoader = DataLoader(dataset_train, batch_size=batch_size, num_workers=5)\n",
        "testLoader = DataLoader(dataset_test, batch_size=4, num_workers=5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mep8IOitL0-2",
        "outputId": "55bfc0c7-c4e0-4c2c-b7d6-d9b43cec3a71"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data_iter = iter(testLoader)\n",
        "\n",
        "inputs, labels = data_iter.next()\n",
        "\n",
        "print(inputs['input_ids'])\n",
        "print(inputs['attention_mask'])\n",
        "print(torch.masked_select(inputs['input_ids'], inputs['attention_mask'].bool()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[    2,  2104,   287,     3,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0]],\n",
            "\n",
            "        [[    2,    43,  4090,  4253, 13927,  4105,  4091, 19802,  4130, 32150,\n",
            "           4253,  4169,  4013, 13352,  4053,  4101,  4015,     3,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0]],\n",
            "\n",
            "        [[    2,  2702,  4474,  3240, 18790,  4006,  4112,    18,    18,    18,\n",
            "             18, 10523,  4189,  3083, 17164,  6242,  4469,  8089,  4034, 15741,\n",
            "           6231, 14903,     3,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0]],\n",
            "\n",
            "        [[    2, 13070,  4279,  4200,  4034,  3083,  4112,  4244,  7772, 18274,\n",
            "           4594,    18,    18,    18,  2398,  4076,  4219,  2780, 12633,  4034,\n",
            "             18,    18,    18,    18,     3,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "              0,     0,     0,     0]]])\n",
            "tensor([[[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])\n",
            "tensor([    2,  2104,   287,     3,     2,    43,  4090,  4253, 13927,  4105,\n",
            "         4091, 19802,  4130, 32150,  4253,  4169,  4013, 13352,  4053,  4101,\n",
            "         4015,     3,     2,  2702,  4474,  3240, 18790,  4006,  4112,    18,\n",
            "           18,    18,    18, 10523,  4189,  3083, 17164,  6242,  4469,  8089,\n",
            "         4034, 15741,  6231, 14903,     3,     2, 13070,  4279,  4200,  4034,\n",
            "         3083,  4112,  4244,  7772, 18274,  4594,    18,    18,    18,  2398,\n",
            "         4076,  4219,  2780, 12633,  4034,    18,    18,    18,    18,     3])\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ_149GPEQWK",
        "outputId": "dafb048b-6a6a-48ba-a3dc-df9edf623837"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# To test tokenizer works correct, reverse data\n",
        "\n",
        "tokenizer.convert_ids_to_tokens(dataset_test[0][0]['input_ids'][0])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " '굳',\n",
              " 'ㅋ',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2S6Q5kGb1sv",
        "outputId": "4b6a9551-e86c-4b5f-fb14-820bae7195d4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Test model\n",
        "\n",
        "output = electra(input_ids=dataset_test[0][0]['input_ids'], attention_mask=dataset_test[0][0]['attention_mask'])\n",
        "\n",
        "# Output of Electra is sequence_output, (hidden_states), (attentions)\n",
        "# To get embeddign of [CLS] token, sequence_output[0][:, 0]\n",
        "output[0][:, 0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.5897e-01,  2.1238e-01, -1.9421e-01, -1.7494e-02, -5.3885e-02,\n",
              "         -6.5732e-01,  2.8845e-01, -7.6507e-01, -2.2635e-01, -5.7455e-01,\n",
              "          2.6866e-01,  2.9759e-02, -2.9668e-01, -1.4651e-01, -1.2856e-01,\n",
              "         -2.9700e-01, -4.0587e-01, -8.9296e-01,  4.5421e-01, -1.4678e-01,\n",
              "          5.6161e+00,  2.3460e-01,  5.6136e-01, -2.9567e-01, -2.8435e-01,\n",
              "          3.0903e-01, -6.6090e-02,  5.0799e-01,  3.1083e-01,  3.4927e-01,\n",
              "         -1.6204e-01,  7.1948e-02,  2.1798e-01,  3.0923e-01,  1.2292e-01,\n",
              "         -2.8467e-01,  2.2177e-01,  4.7371e-01,  6.1875e-02, -1.3758e-01,\n",
              "          1.9191e-01,  6.1975e-02,  2.6209e-01,  3.6230e-01, -2.8800e-01,\n",
              "          2.2081e-01, -2.9396e-01,  1.9164e-02,  4.0434e-01, -2.6254e-01,\n",
              "         -7.9893e-02, -1.1736e-01, -2.5994e-01, -5.4133e-01, -2.2002e-02,\n",
              "         -1.6750e-02,  5.9630e-01, -3.4271e-01,  8.9398e-04,  5.9024e-01,\n",
              "         -3.5799e-01, -3.5881e-01,  4.3400e-01, -1.0047e-01,  3.6890e-01,\n",
              "          1.6900e-01,  4.3253e-03,  1.7030e-01,  9.8747e-02, -5.5533e-01,\n",
              "          1.7624e-01, -1.0653e-01,  1.0256e-01, -1.9239e-01,  2.2653e-01,\n",
              "          8.6279e-02,  8.4599e-02, -2.0079e-01, -2.7202e-01, -2.3552e-03,\n",
              "          2.0564e-01,  3.6644e-01, -2.0929e-01, -1.3964e-01,  2.0874e-01,\n",
              "          1.5173e-02,  3.3354e-01, -3.9153e-01,  4.0108e-01,  2.2634e-01,\n",
              "          1.2786e-01, -1.6477e-02, -8.8490e-02,  1.0449e-01, -2.3538e-01,\n",
              "         -5.6689e-01, -1.8498e-01, -3.6059e-02,  3.2784e-01,  9.6947e-02,\n",
              "         -1.2879e-02,  2.7492e-01, -4.4510e-01,  1.8258e-01,  4.3713e-02,\n",
              "          4.1421e-01,  8.7013e-01,  2.2251e-02,  2.3577e-01,  2.3304e-01,\n",
              "         -2.6483e-01,  8.0690e-02, -3.1752e-01,  7.9540e-02,  7.1566e-02,\n",
              "          8.6185e-02, -1.8283e-01, -5.8538e-01,  4.8980e-01, -2.5294e-01,\n",
              "          2.4515e-01, -2.6478e-01,  3.1335e-01, -3.0815e-01, -4.0125e-01,\n",
              "          4.2750e-01,  7.5306e-03, -2.1187e-01, -3.8508e-02,  5.8046e-01,\n",
              "         -3.5595e-01,  1.6768e-02,  2.2280e-01, -4.2961e-01,  6.9167e-01,\n",
              "          4.5801e-01, -4.1031e-01, -3.8775e-01,  1.0086e-01,  6.0885e-02,\n",
              "          1.3644e-01,  5.5775e-01, -5.1178e-02, -1.6198e-01,  6.0000e-01,\n",
              "          2.5647e-01, -4.6712e-02,  4.8559e-01,  1.6348e-01,  5.6447e-01,\n",
              "          3.8797e-01,  1.2088e-01, -3.7495e-01, -2.6539e-02, -7.9224e-03,\n",
              "          3.4149e-01,  4.1154e-01,  1.3765e-01, -3.6834e-01, -5.0134e-01,\n",
              "          3.8179e-01,  4.4731e-01,  5.6600e-01, -1.4139e-02, -1.5503e-01,\n",
              "         -2.6586e-01, -1.0478e-01, -2.6574e-01,  7.0568e-02, -6.2538e-02,\n",
              "         -6.1508e-01,  3.2812e-01, -1.8479e-01,  5.1279e-01,  1.6039e-01,\n",
              "          4.4999e-01, -2.5838e-01,  4.7150e-01, -4.2255e-01,  4.7795e-02,\n",
              "         -3.4890e-01,  1.0867e-01,  1.7603e-01, -1.9136e-01, -4.3137e-01,\n",
              "          1.3133e-01, -2.7286e-01, -1.9265e-01,  7.6123e-02,  3.3349e-01,\n",
              "          1.8305e-01,  6.7453e-02, -5.3894e-01,  2.5292e-02, -8.4867e-02,\n",
              "          2.3547e-01,  1.0282e-01,  5.1202e-01,  3.1635e-01, -4.4934e-01,\n",
              "          3.8943e-01, -2.7877e-01,  3.1004e-01, -1.7210e-01, -6.1977e-02,\n",
              "          3.8142e-01, -1.1120e-01,  2.0991e-01, -6.3707e-01,  3.1707e-02,\n",
              "         -1.8444e-01,  3.0068e-01,  4.6553e-01, -5.7078e-01,  5.9031e-01,\n",
              "         -5.7763e-02, -5.4977e-02, -1.4871e-01,  5.0695e-01, -6.6261e-01,\n",
              "         -4.8830e-01, -2.8920e-01, -1.7695e-01,  7.3473e-01, -4.8350e-02,\n",
              "         -2.8176e-02, -1.0503e-01, -2.2896e-01,  4.0993e-02, -2.1187e-01,\n",
              "         -7.5173e-02,  3.4969e-01, -3.4788e-02, -1.6438e-01, -4.6539e-01,\n",
              "          4.4634e-02, -3.4204e-02,  9.8587e-03, -1.4556e-01, -8.7682e-02,\n",
              "          9.6532e-01,  8.5879e-01, -4.2147e-01, -5.3049e-01, -6.5156e-02,\n",
              "         -5.1369e-01,  1.7399e-01, -1.9456e-01,  1.4224e-01,  1.1667e-01,\n",
              "         -3.8326e-01, -3.1550e-01,  2.6635e-01,  3.8415e-01, -3.8319e-01,\n",
              "          7.4456e-01]], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY-eRYVTsA0i",
        "outputId": "c2450c55-4f77-4b1c-8e65-dc3f75d66f90"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "only_pad = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1]])\n",
        "attention = torch.tensor([[0, 0, 0, 0, 0, 0, 0, 0]])\n",
        "\n",
        "output = electra(input_ids=only_pad, attention_mask=attention)\n",
        "out = output[0][:, 0]\n",
        "out"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7.1112e-01, -4.9163e-02, -1.8260e-01, -1.5657e-01, -1.6857e-01,\n",
              "         -1.1118e-01,  2.7091e-01, -6.2547e-01,  1.4038e-01, -9.5232e-01,\n",
              "          4.8027e-01,  3.1133e-01, -5.3059e-01, -2.7934e-01, -1.2518e-01,\n",
              "         -4.4102e-01, -8.2895e-02, -1.5149e+00,  8.4931e-01, -3.4192e-01,\n",
              "          5.1139e+00,  5.7319e-01,  3.2024e-01, -1.7249e-01, -2.6766e-01,\n",
              "          4.9328e-01, -3.1484e-02,  6.4242e-01, -1.9585e-01,  2.7669e-01,\n",
              "         -1.5954e-01, -2.4577e-01,  3.6091e-01,  1.9536e-01,  5.3041e-01,\n",
              "          1.8003e-01, -3.1870e-02,  1.3203e-01, -1.7484e-01,  2.5658e-01,\n",
              "          9.0250e-02, -4.1634e-02,  3.9124e-01,  7.7824e-01, -2.3612e-01,\n",
              "          2.2406e-02, -5.0491e-01, -2.7234e-01, -3.5927e-02, -3.9452e-01,\n",
              "         -8.9301e-02, -7.4678e-02, -2.5207e-01, -6.3218e-01,  2.9558e-02,\n",
              "          2.4450e-01,  4.1014e-01,  4.5775e-02,  2.3371e-01,  2.7414e-02,\n",
              "         -1.1391e-01, -6.6699e-02,  6.8913e-01, -7.8566e-02,  8.9245e-02,\n",
              "         -9.8181e-02, -3.0599e-02,  3.3880e-01, -1.7208e-01, -2.7604e-01,\n",
              "          5.0573e-02, -1.2927e-02,  1.5007e-01, -1.3116e-01,  1.6544e-01,\n",
              "         -1.5225e-02,  1.8406e-02, -1.0442e-01, -4.9174e-02, -3.2420e-01,\n",
              "          4.5208e-01,  5.9253e-02, -3.4444e-01, -3.0064e-01,  1.6192e-01,\n",
              "         -3.9648e-01, -1.3557e-01, -3.4514e-01,  2.1315e-01,  5.6296e-01,\n",
              "         -8.9564e-02, -1.1006e-02,  1.8928e-01, -5.5815e-02, -2.0521e-01,\n",
              "         -3.6238e-01, -1.1819e-02,  1.1906e-01,  4.8737e-01,  1.3874e-01,\n",
              "          6.1639e-02, -7.1371e-02, -4.6631e-01,  4.7800e-01,  3.1919e-01,\n",
              "          6.1355e-01,  7.8572e-01, -1.7610e-01,  2.5125e-01,  9.4828e-02,\n",
              "         -9.7733e-02, -1.7968e-01, -2.6741e-01,  2.8828e-01,  9.1992e-02,\n",
              "         -2.3919e-01,  2.3130e-01, -6.9574e-01,  6.7218e-01, -4.3377e-01,\n",
              "          1.8088e-01, -4.3015e-01,  4.2997e-01, -3.7357e-01, -4.5789e-01,\n",
              "          3.5250e-01, -7.1906e-02, -1.1814e-01,  6.2599e-02,  6.2155e-01,\n",
              "         -3.0010e-01, -1.1913e-01,  4.0104e-01, -3.0642e-01,  7.4044e-01,\n",
              "          3.1332e-01, -3.5063e-01, -1.7921e-01,  1.0327e-01,  8.3115e-02,\n",
              "          3.9124e-01,  4.2707e-01,  1.5103e-01, -8.7786e-02,  3.6181e-01,\n",
              "          6.5633e-01,  3.9456e-01,  8.1660e-01,  2.3950e-01,  2.9869e-01,\n",
              "          4.8680e-01, -1.1475e-01, -3.0688e-01,  4.9383e-03, -1.7750e-01,\n",
              "          1.8699e-01,  3.0467e-01,  2.2988e-01, -1.1173e-01, -8.9606e-01,\n",
              "          2.6568e-01,  3.5297e-01,  6.2055e-01, -2.9649e-01,  4.6352e-02,\n",
              "         -4.5601e-01, -2.6073e-01, -9.8061e-02,  5.4529e-02, -4.7533e-01,\n",
              "         -7.6604e-01,  1.4076e-01,  5.4170e-01,  6.0207e-01,  1.5058e-01,\n",
              "          3.5421e-01, -2.6564e-01,  4.9544e-01,  4.7896e-03,  6.6052e-03,\n",
              "          1.5793e-01,  5.6318e-02,  2.1943e-01, -4.6403e-01, -1.3563e-01,\n",
              "          1.7859e-01, -1.8760e-01,  1.6503e-01,  1.0195e-01, -6.3903e-02,\n",
              "          5.1033e-01, -1.3986e-01, -7.3033e-01, -1.1550e-01, -2.0227e-01,\n",
              "          2.5876e-01,  3.0228e-02,  6.1752e-01,  3.2338e-01, -4.1724e-01,\n",
              "          5.2517e-01, -1.6425e-01, -8.3780e-02, -2.3849e-01, -6.1333e-01,\n",
              "          1.6562e-02,  1.3706e-01,  2.9135e-01, -6.1431e-01, -1.3982e-01,\n",
              "         -4.5621e-01, -1.0765e-01,  4.6289e-01, -5.9489e-01,  8.3543e-01,\n",
              "          1.5955e-02, -2.6935e-01,  1.3317e-01,  4.5992e-01, -1.7952e-01,\n",
              "         -2.3096e-01, -1.2282e-01, -3.7823e-01,  4.8742e-01, -7.2033e-02,\n",
              "          8.8401e-02,  5.8553e-02, -1.4762e-01,  1.6885e-02,  1.9351e-01,\n",
              "          7.3657e-02,  2.9450e-01, -4.9943e-01, -5.0863e-02, -5.1525e-01,\n",
              "          6.1667e-01, -1.6648e-01, -1.3034e-01,  4.1785e-02, -2.1327e-01,\n",
              "          8.5890e-01,  7.6599e-01, -6.5955e-02, -8.2961e-01, -3.5539e-01,\n",
              "         -6.9063e-01,  1.8956e-01,  5.3576e-02,  7.4484e-03,  5.5682e-01,\n",
              "          1.3027e-02, -5.7286e-01, -7.0556e-02,  1.7432e-01, -5.1698e-01,\n",
              "          8.7096e-01]], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9drKEI9m7bu",
        "outputId": "a8aaa28e-6e1d-4fe8-b6b7-77594ed142ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Mdoel\n",
        "\n",
        "Electra model itself is not predication model. It is more like embedding model. \\\n",
        "To predict review rating, we need to construct classification model based on Electra."
      ],
      "metadata": {
        "id": "UYVOF5MAP0l2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self, electra, hidden_layers=[512], num_classes=2):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    --------------\n",
        "\n",
        "    electra : Electra model\n",
        "      Electra Model to imbed input text\n",
        "    hidden_layers : list(int)\n",
        "      Layers of classifier, each int is size of each layers\n",
        "    num_classes : int\n",
        "      output classes\n",
        "    \"\"\"\n",
        "    super(Classifier, self).__init__()\n",
        "    self.electra = electra\n",
        "\n",
        "    for param in self.electra.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    layers = []\n",
        "    # Output size of electra model\n",
        "    input_size = 256\n",
        "\n",
        "    layers += [nn.BatchNorm1d(input_size),\n",
        "               nn.ReLU(inplace=True)]\n",
        "\n",
        "    for layer_size in hidden_layers:\n",
        "      layers += [nn.Linear(input_size, layer_size),\n",
        "                          nn.BatchNorm1d(layer_size),\n",
        "                          nn.ReLU(inplace=True),\n",
        "                          nn.Dropout(p=0.5)]\n",
        "\n",
        "      input_size = layer_size\n",
        "    \n",
        "    layers.append(nn.Linear(input_size, num_classes))\n",
        "\n",
        "    self.hidden = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    x = self.electra(input_ids=input_ids, attention_mask=attention_mask)[0][:, 0]\n",
        "\n",
        "    x = self.hidden(x)\n",
        "\n",
        "    return x\n",
        "    "
      ],
      "outputs": [],
      "metadata": {
        "id": "yuvTR5TDQMbe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = Classifier(electra).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134146"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "metadata": {
        "id": "WLGpAVIhKugy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fe2bd1-e063-4e67-c04e-05441bc34e02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model\n"
      ],
      "metadata": {
        "id": "bzqeF1ynPKxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "opt = optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "5igZFV31PvXm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Cal_accuracy(pred, y):\n",
        "  pred_label = torch.argmax(pred, dim=1)\n",
        "  acc = (pred_label == y).sum().data.cpu() / (len(y) + 1)\n",
        "  return acc"
      ],
      "outputs": [],
      "metadata": {
        "id": "KQ_XUPWoyuSk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# To plot loss save losses\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for e in range(epoch):\n",
        "  model.train()\n",
        " \n",
        "  i = 0\n",
        "  for inputs, labels in trainLoader:\n",
        "    opt.zero_grad()\n",
        "\n",
        "    input_ids = inputs['input_ids'].squeeze().to(device)\n",
        "    attention_mask = inputs['attention_mask'].squeeze().to(device)\n",
        "\n",
        "    labels = labels.squeeze().to(device)\n",
        "\n",
        "    pred = model(input_ids, attention_mask)\n",
        "    loss = loss_fn(pred, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "    opt.step()\n",
        "\n",
        "    train_loss.append(loss.mean().data.cpu())\n",
        "    acc = Cal_accuracy(pred, labels)\n",
        "\n",
        "    i += 1\n",
        "    if (i % log_interval) == 0:\n",
        "      print(f\"epoch {e} train_loss {loss.data.cpu()} acc {acc}\")\n",
        "  \n",
        "  model.eval()\n",
        "  i = 0\n",
        "  losses = 0\n",
        "  acc = 0\n",
        "  for inputs, labels in testLoader:\n",
        "    input_ids = inputs['input_ids'].squeeze().to(device)\n",
        "    attention_mask = inputs['attention_mask'].squeeze().to(device)\n",
        "\n",
        "    labels = labels.squeeze().to(device)\n",
        "\n",
        "    pred = model(input_ids, attention_mask)\n",
        "    loss = loss_fn(pred, labels)\n",
        "    losses += loss.sum().data.cpu()\n",
        "    acc += Cal_accuracy(pred, labels)\n",
        "\n",
        "    test_loss.append(loss.mean().data.cpu())\n",
        "    i += 1\n",
        "  \n",
        "  losses = losses / (batch_size * i)\n",
        "  acc = acc / i\n",
        "\n",
        "  print(f\"epoch {e} test_loss {losses} acc {acc}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train_loss 0.6626798510551453 acc 0.5736433863639832\n",
            "epoch 0 train_loss 0.6159391403198242 acc 0.6589147448539734\n",
            "epoch 0 test_loss 0.004577093757688999 acc 0.5470238924026489\n",
            "epoch 1 train_loss 0.5982567071914673 acc 0.6666666865348816\n",
            "epoch 1 train_loss 0.6167879104614258 acc 0.6201550364494324\n",
            "epoch 1 test_loss 0.004449367057532072 acc 0.5583352446556091\n",
            "epoch 2 train_loss 0.6242090463638306 acc 0.6666666865348816\n",
            "epoch 2 train_loss 0.611432671546936 acc 0.6589147448539734\n",
            "epoch 2 test_loss 0.004382772371172905 acc 0.5639028549194336\n",
            "epoch 3 train_loss 0.5624515414237976 acc 0.7054263353347778\n",
            "epoch 3 train_loss 0.6392976641654968 acc 0.6666666865348816\n",
            "epoch 3 test_loss 0.004358114209026098 acc 0.5672302842140198\n",
            "epoch 4 train_loss 0.6076874732971191 acc 0.6356589198112488\n",
            "epoch 4 train_loss 0.6213057041168213 acc 0.643410861492157\n",
            "epoch 4 test_loss 0.00433066301047802 acc 0.5668623447418213\n"
          ]
        }
      ],
      "metadata": {
        "id": "8qNCbckHPMEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f162b7-21a0-4187-de31-018e489ad7db"
      }
    }
  ]
}